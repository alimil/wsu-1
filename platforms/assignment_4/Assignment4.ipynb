{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "YLCtcwSCmeGz",
    "outputId": "146a8c59-44e6-40db-c3c4-1c08af0dc11c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: apt-get: command not found\n",
      "--2019-04-08 21:47:07--  http://apache.osuosl.org/spark/spark-2.4.1/spark-2.4.1-bin-hadoop2.7.tgz\n",
      "Resolving apache.osuosl.org (apache.osuosl.org)... 64.50.233.100, 64.50.236.52, 140.211.166.134, ...\n",
      "Connecting to apache.osuosl.org (apache.osuosl.org)|64.50.233.100|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 230778742 (220M) [application/x-gzip]\n",
      "Saving to: ‘spark-2.4.1-bin-hadoop2.7.tgz’\n",
      "\n",
      "spark-2.4.1-bin-had 100%[===================>] 220.09M  11.2MB/s    in 20s     \n",
      "\n",
      "2019-04-08 21:47:27 (11.3 MB/s) - ‘spark-2.4.1-bin-hadoop2.7.tgz’ saved [230778742/230778742]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
    "![ ! -e \"$(basename spark-2.4.1-bin-hadoop2.7.tgz)\" ] && wget  http://apache.osuosl.org/spark/spark-2.4.1/spark-2.4.1-bin-hadoop2.7.tgz\n",
    "!tar xf spark-2.4.1-bin-hadoop2.7.tgz\n",
    "!pip install -q findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l6yH8VATnKiN"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.1-bin-hadoop2.7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V61ecorTnQKK"
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-815899e9d54d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfindspark\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfindspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# get a spark session.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/secret/wsu/ds/lib/python3.7/site-packages/findspark.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(spark_home, python_path, edit_rc, edit_profile)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;31m# add pyspark to sys.path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0mspark_python\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspark_home\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m     \u001b[0mpy4j\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspark_python\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'py4j-*.zip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mspark_python\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# get a spark session. \n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "lYdU0VDXmNhL",
    "outputId": "cf23d14a-5e2e-4430-b5d9-b17c30240ada"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Reporting Area', 'MMWR Year', 'MMWR Week', 'Salmonellosis (excluding Paratyphoid fever andTyphoid fever)†, Current week', 'Salmonellosis (excluding Paratyphoid fever andTyphoid fever)†, Current week, flag', 'Salmonellosis (excluding Paratyphoid fever andTyphoid fever)†, Previous 52 weeks Med', 'Salmonellosis (excluding Paratyphoid fever andTyphoid fever)†, Previous 52 weeks Med, flag', 'Salmonellosis (excluding Paratyphoid fever andTyphoid fever)†, Previous 52 weeks Max', 'Salmonellosis (excluding Paratyphoid fever andTyphoid fever)†, Previous 52 weeks Max, flag', 'Salmonellosis (excluding Paratyphoid fever andTyphoid fever)†, Cum 2018', 'Salmonellosis (excluding Paratyphoid fever andTyphoid fever)†, Cum 2018, flag', 'Salmonellosis (excluding Paratyphoid fever andTyphoid fever)†, Cum 2017', 'Salmonellosis (excluding Paratyphoid fever andTyphoid fever)†, Cum 2017, flag', 'Shiga toxin-producing Escherichia coli, Current week', 'Shiga toxin-producing Escherichia coli, Current week, flag', 'Shiga toxin-producing Escherichia coli, Previous 52 weeks Med', 'Shiga toxin-producing Escherichia coli, Previous 52 weeks Med, flag', 'Shiga toxin-producing Escherichia coli, Previous 52 weeks Max', 'Shiga toxin-producing Escherichia coli, Previous 52 weeks Max, flag', 'Shiga toxin-producing Escherichia coli, Cum 2018', 'Shiga toxin-producing Escherichia coli, Cum 2018, flag', 'Shiga toxin-producing Escherichia coli, Cum 2017', 'Shiga toxin-producing Escherichia coli, Cum 2017, flag', 'Shigellosis, Current week', 'Shigellosis, Current week, flag', 'Shigellosis, Previous 52 weeks Med', 'Shigellosis, Previous 52 weeks Med, flag', 'Shigellosis, Previous 52 weeks Max', 'Shigellosis, Previous 52 weeks Max, flag', 'Shigellosis, Cum 2018', 'Shigellosis, Cum 2018, flag', 'Shigellosis, Cum 2017', 'Shigellosis, Cum 2017, flag']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dfss = spark.read.csv(\"ss.csv\", header= True, \n",
    "                      inferSchema = True)\n",
    "\n",
    "print(dfss.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "SgANC-8Svx-O",
    "outputId": "5b882686-a36b-4c3f-9f66-48befb7cde40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Reporting Area', 'MMWR Year', 'MMWR Week', 'Giardiasis, Current week', 'Giardiasis, Current week, flag', 'Giardiasis, Previous 52 weeks Med', 'Giardiasis, Previous 52 weeks Med, flag', 'Giardiasis, Previous 52 weeks Max', 'Giardiasis, Previous 52 weeks Max, flag', 'Giardiasis, Cum 2017', 'Giardiasis, Cum 2017, flag', 'Giardiasis, Cum 2016', 'Giardiasis, Cum 2016, flag', 'Gonorrhea,Current week', 'Gonorrhea,Current week, flag', 'Gonorrhea,Previous 52 weeks Med', 'Gonorrhea,Previous 52 weeks Med, flag', 'Gonorrhea, Previous 52 weeks Max', 'Gonorrhea, Previous 52 weeks Max, flag', 'Gonorrhea, Cum 2017', 'Gonorrhea, Cum 2017, flag', 'Gonorrhea, Cum 2016', 'Gonorrhea, Cum 2016, flag', 'Haemophilus influenzae invasive§, All ages, all serotypes, Current week', 'Haemophilus influenzae invasive§, All ages, all serotypes, Current week, flag', 'Haemophilus influenzae invasive§, All ages, all serotypes, Previous 52 weeks Med', 'Haemophilus influenzae invasive§, All ages, all serotypes, Previous 52 weeks Med, flag', 'Haemophilus influenzae invasive§, All ages, all serotypes, Previous 52 weeks Max', 'Haemophilus influenzae invasive§, All ages, all serotypes, Previous 52 weeks Max, flag', 'Haemophilus influenzae invasive§, All ages, all serotypes, Cum 2017', 'Haemophilus influenzae invasive§, All ages, all serotypes, Cum 2017, flag', 'Haemophilus influenzae invasive§, All ages, all serotypes, Cum 2016', 'Haemophilus influenzae invasive§, All ages, all serotypes, Cum 2016, flag']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dfgh = spark.read.csv(\"gh.csv\", header= True, \n",
    "                      inferSchema = True)\n",
    "\n",
    "print(dfgh.columns)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment4.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
