{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment4.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/borodark/wsu/blob/master/wsu/platforms/assignment_4/Assignment4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "YLCtcwSCmeGz",
        "colab_type": "code",
        "outputId": "146a8c59-44e6-40db-c3c4-1c08af0dc11c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "![ ! -e \"$(basename spark-2.4.1-bin-hadoop2.7.tgz)\" ] && wget  http://apache.osuosl.org/spark/spark-2.4.1/spark-2.4.1-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.1-bin-hadoop2.7.tgz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-04-09 00:58:38--  http://apache.osuosl.org/spark/spark-2.4.1/spark-2.4.1-bin-hadoop2.7.tgz\n",
            "Resolving apache.osuosl.org (apache.osuosl.org)... 64.50.236.52, 140.211.166.134, 64.50.233.100, ...\n",
            "Connecting to apache.osuosl.org (apache.osuosl.org)|64.50.236.52|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 230778742 (220M) [application/x-gzip]\n",
            "Saving to: ‘spark-2.4.1-bin-hadoop2.7.tgz’\n",
            "\n",
            "spark-2.4.1-bin-had 100%[===================>] 220.09M  26.1MB/s    in 13s     \n",
            "\n",
            "2019-04-09 00:58:51 (17.0 MB/s) - ‘spark-2.4.1-bin-hadoop2.7.tgz’ saved [230778742/230778742]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "omNkhAwl2V21",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -q findspark"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l6yH8VATnKiN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.1-bin-hadoop2.7\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V61ecorTnQKK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# get a spark session. \n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lYdU0VDXmNhL",
        "colab_type": "code",
        "outputId": "2dd4eca3-2827-4598-a328-582cf584a5c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "ss_ = spark.read.csv(\"ss.csv\", header= True, \n",
        "                      inferSchema = True)\n",
        "\n",
        "columns_lambda = lambda k: k.endswith(', Current week') or k == 'Reporting Area' or k == 'MMWR Year' or  k == 'MMWR Week'\n",
        "\n",
        "sss = filter(columns_lambda, ss_.columns)\n",
        "\n",
        "\n",
        "to_keep = list(sss)\n",
        "\n",
        "dfss = ss_.select(*to_keep)\n",
        "dfss.columns"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Reporting Area',\n",
              " 'MMWR Year',\n",
              " 'MMWR Week',\n",
              " 'Salmonellosis (excluding Paratyphoid fever andTyphoid fever)†, Current week',\n",
              " 'Shiga toxin-producing Escherichia coli, Current week',\n",
              " 'Shigellosis, Current week']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "metadata": {
        "id": "SgANC-8Svx-O",
        "colab_type": "code",
        "outputId": "33dd93f9-f0f7-47dc-9f76-8c213bf476dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "gh_ = spark.read.csv(\"gh.csv\", header= True, \n",
        "                      inferSchema = True)\n",
        "\n",
        "sss = filter(columns_lambda, gh_.columns)\n",
        "\n",
        "\n",
        "to_keep = list(sss)\n",
        "\n",
        "ghss = gh_.select(*to_keep)\n",
        "ghss.columns\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Reporting Area',\n",
              " 'MMWR Year',\n",
              " 'MMWR Week',\n",
              " 'Giardiasis, Current week',\n",
              " 'Haemophilus influenzae invasive§, All ages, all serotypes, Current week']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "metadata": {
        "id": "Dnvtmvp8UFl6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "ac3946a9-7542-4481-934e-6c0f7847538f"
      },
      "cell_type": "code",
      "source": [
        "ch_ = spark.read.csv(\"ch.csv\", header= True, \n",
        "                      inferSchema = True)\n",
        "\n",
        "sss = filter(columns_lambda, ch_.columns)\n",
        "\n",
        "\n",
        "to_keep = list(sss)\n",
        "\n",
        "chss = ch_.select(*to_keep)\n",
        "chss.columns"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Reporting Area',\n",
              " 'MMWR Year',\n",
              " 'MMWR Week',\n",
              " 'Chlamydia trachomatis infection, Current week',\n",
              " 'Coccidioidomycosis, Current week']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    }
  ]
}